# reverse search and google search plugin for yamenthon
import contextlib
import os
import re
import urllib
from datetime import datetime
import asyncio
import random

import requests
from bs4 import BeautifulSoup
from PIL import Image
from search_engine_parser import BingSearch, GoogleSearch, YahooSearch
from search_engine_parser.core.exceptions import NoResultsOrTrafficError

from . import BOTLOG, BOTLOG_CHATID, Convert, zedub

from ..Config import Config
from ..core.managers import edit_delete, edit_or_reply
from ..helpers.functions import deEmojify
from ..helpers.utils import reply_id

opener = urllib.request.build_opener()
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)",
    "Mozilla/5.0 (X11; Ubuntu; Linux x86_64)",
]
# Ø§Ø®ØªÙØ± User-Agent Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙˆÙ„ (ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¥Ù† Ø£Ø±Ø¯Øª ØªØ¯ÙˆÙŠØ± ÙƒÙ„ Ø·Ù„Ø¨)
opener.addheaders = [("User-Agent", random.choice(user_agents))]

plugin_category = "Ø§Ù„Ø¨Ø­Ø«"


async def ParseSauce(googleurl):
    """Parse/Scrape the HTML code for the info we want."""
    # Ù†Ø³ØªØ®Ø¯Ù… opener (Ù…Ø¹ User-Agent Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø£Ø¹Ù„Ø§Ù‡)
    source = opener.open(googleurl).read()
    soup = BeautifulSoup(source, "html.parser")
    results = {"similar_images": "", "best_guess": ""}
    with contextlib.suppress(BaseException):
        for similar_image in soup.findAll("input", {"class": "gLFyf"}):
            url = "https://www.google.com/search?tbm=isch&q=" + urllib.parse.quote_plus(
                similar_image.get("value")
            )
            results["similar_images"] = url
    for best_guess in soup.findAll("div", attrs={"class": "r5a77d"}):
        results["best_guess"] = best_guess.get_text()
    return results


async def scam(results, lim):
    """
    ÙŠÙ‚Ø±Ø£ ØµÙØ­Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ù…Ø§Ø«Ù„Ø© Ø§Ù„ØªÙŠ Ø­ØµÙ„Ù†Ø§ Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ù† ParseSauce Ø«Ù… ÙŠØ¬Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ±.
    Ø£Ø¶ÙÙ†Ø§ sleep Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¨ÙŠÙ† ÙƒÙ„ Ø·Ù„Ø¨ Ù„ØªØ®ÙÙŠÙ Ø§Ù„Ø¶ØºØ· ÙˆØªÙ‚Ù„ÙŠÙ„ ÙØ±Øµ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ 429.
    """
    single = opener.open(results["similar_images"]).read()
    decoded = single.decode("utf-8")
    imglinks = []
    counter = 0
    pattern = r"^,\[\"(.*[.png|.jpg|.jpeg])\",[0-9]+,[0-9]+\]$"
    oboi = re.findall(pattern, decoded, re.I | re.M)
    for imglink in oboi:
        counter += 1
        if counter <= int(lim):
            imglinks.append(imglink)
            # ØªØ£Ø®ÙŠØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† Ø·Ù„Ø¨ ÙˆØ¢Ø®Ø± Ø­ØªÙ‰ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ Ø§Ù„Ø§ØªÙ‘ØµØ§Ù„ Ø¨ÙˆØªÙŠ Ø¬Ø¯Ø§Ù‹
            await asyncio.sleep(random.uniform(1.5, 3.5))
        else:
            break
    return imglinks


async def reverse_image_search(image_path, lim=3):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Google Reverse Image Search Ø£ÙˆÙ„Ù‹Ø§.
    Ø¥Ø°Ø§ Ù†Ø¬Ø­: ØªØ±Ø¬Ø¹ ("google", results_dict, fetchUrl)
    Ø¥Ø°Ø§ ÙØ´Ù„ (Ù…Ø«Ù„ 429) â†’ ØªØ±Ø¬Ø¹ fallback Ø±Ø³Ø§Ù„Ø© Ù„Ù€ Bing/Yandex Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ø±ÙˆØ¡:
        ("bing", ["Ø±Ø³Ø§Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ©"], None)
    """
    # Ø¬Ø±Ø¨ Google Ø£ÙˆÙ„Ù‹Ø§
    try:
        # Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªØ¶Ù…Ù† Ø¥ØºÙ„Ø§Ù‚Ù‡
        with open(image_path, "rb") as f:
            multipart = {"encoded_image": (image_path, f), "image_content": ""}
            searchUrl = "https://www.google.com/searchbyimage/upload"
            response = requests.post(searchUrl, files=multipart, allow_redirects=False, timeout=30)

        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø±Ø¯
        # Google Ø¹Ø§Ø¯Ø© ÙŠØ¹ÙŠØ¯ 302 Ù…Ø¹ ØªØ±ÙˆÙŠØ³Ø© Location Ø§Ù„ØªÙŠ ØªÙÙ…Ø«Ù‘Ù„ ØµÙØ­Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if response.status_code == 429:
            # Ø­ÙØ¯Ù‘Ø« Rate limit
            raise Exception("Google rate limit (429)")

        if "Location" not in response.headers:
            # Ù„Ù… Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù†ØªØ§Ø¦Ø¬ Google â€” Ù†Ø¹ØªØ¨Ø±Ù‡Ø§ ÙØ´Ù„
            raise Exception(f"Unexpected Google response: {response.status_code}")

        fetchUrl = response.headers.get("Location")
        # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ParseSauce Ù…Ù† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø©
        results = await ParseSauce(f"{fetchUrl}&preferences?hl=en&fg=1#languages")
        # Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªØ§Ø¦Ø¬ Google Ù…Ø¹ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø© (fetchUrl)
        return ("google", results, fetchUrl)

    except Exception as google_err:
        # Ù„Ùˆ ÙØ´Ù„ Google â€” Ù„Ø§ Ù†Ø­Ø§ÙˆÙ„ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Bing Ù„Ø£Ù† search_engine_parser Ù„Ø§ ÙŠØ¯Ø¹Ù… Reverse Image Ù…Ø¨Ø§Ø´Ø±Ø©
        # Ù„Ø°Ù„Ùƒ Ù†ÙØ±Ø¬Ø¹ Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯ÙŠÙ„Ø© ØªÙ‚ØªØ±Ø­ Ø§Ù„Ø­Ù„ÙˆÙ„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (fallback)
        try:
            # Ø¨Ø¯ÙŠÙ„ Ù†ØµÙŠ: Ù†Ø³ØªØ®Ø¯Ù… Bing/GSearch text search ÙƒØ­Ù„ Ù…Ø¤Ù‚Øª (Ù„Ù† ÙŠÙƒÙˆÙ† Ø¨Ø­Ø« Ø¹ÙƒØ³ÙŠ Ø­Ù‚ÙŠÙ‚ÙŠ)
            # Ù„ÙƒÙ† Ù†Ø³ØªØ·ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ "Ø£Ù‚Ø±Ø¨ ÙˆØµÙ" Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø£Ùˆ ØªØ­Ø°ÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            # Ù‡Ù†Ø§ Ø³Ù†ÙØ¹ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ù„Ù€ Bing
            bing_msg = [
                "ØªØ¹Ø°Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Google (Ø³Ø¨Ø¨: {}).".format(str(google_err)),
                "ÙƒØ­Ù„ Ù…Ø¤Ù‚Øª: Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ ÙÙŠ Bing Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Yandex reverse image Ø¹Ø¨Ø± Ø§Ù„Ù…ØªØµÙØ­.",
                "Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…ÙƒØªØ¨Ø© search_engine_parser Ù„Ø§ ØªØ¯Ø¹Ù… Ø±ÙØ¹ ØµÙˆØ± Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ ÙÙŠ BingØŒ Ù„Ø°Ù„Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙŠØ¯ÙˆÙŠ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ."
            ]
            return ("bing", bing_msg, None)
        except Exception:
            # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ Ù†Ø¹ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© Ù…ÙˆØ­Ù‘Ø¯Ø©
            return ("yandex", ["Ù…Ø§ Ù‚Ø¯Ø±Øª Ø£Ø¬ÙŠØ¨ Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Google Ø£Ùˆ Bing ğŸ˜… â€” Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙŠØ¯ÙˆÙŠ ÙÙŠ Yandex Ø£Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±."], None)


@zedub.zed_cmd(
    pattern="Ø¬Ùˆ ([\s\S]*)",
    command=("Ø¬Ùˆ", plugin_category),
    info={
        "header": "Google search command.",
        "Ø§Ù…Ø± Ù…Ø¶Ø§Ù": {
            "-l": "for number of search results.",
            "-p": "for choosing which page results should be showed.",
        },
        "Ø§Ù„Ø§Ø³Ù€ØªØ®Ù€Ø¯Ø§Ù…": [
            "{tr}Ø¬Ùˆ + Ø§Ù„Ø§Ù…Ø± Ø§Ù„Ù…Ø¶Ø§Ù + ÙƒÙ„Ù…Ù€Ù‡",
            "{tr}Ø¬Ùˆ + ÙƒÙ„Ù…Ù€Ù‡",
        ],
        "Ù…Ø«Ù€Ù€Ø§Ù„": [
            "{tr}Ø¬Ùˆ ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†",
            "{tr}Ø¬Ùˆ Ø¹Ø¯Ø¯6 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†",
            "{tr}Ø¬Ùˆ ØµÙØ­Ù‡2 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†",
            "{tr}Ø¬Ùˆ ØµÙØ­Ù‡2 Ø¹Ø¯Ø¯7 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†",
        ],
    },
)
async def gsearch(q_event):
    "Google search command."
    zedevent = await edit_or_reply(q_event, "**- Ø¬Ù€Ø§Ø±Ù Ø§Ù„Ø¨Ø­Ù€Ø« ÙÙŠ Ø¬ÙˆØ¬Ù€Ù€Ù„...**")
    match = q_event.pattern_match.group(1)
    page = re.findall(r"ØµÙØ­Ù‡\d+", match)
    lim = re.findall(r"Ø¹Ø¯Ø¯\d+", match)
    try:
        page = page[0]
        page = page.replace("ØµÙØ­Ù‡", "")
        match = match.replace(f"ØµÙØ­Ù‡{page}", "")
    except IndexError:
        page = 1
    try:
        lim = lim[0]
        lim = lim.replace("Ø¹Ø¯Ø¯", "")
        match = match.replace(f"Ø¹Ø¯Ø¯{lim}", "")
        lim = int(lim)
        if lim <= 0:
            lim = 5
    except IndexError:
        lim = 5
    #     smatch = urllib.parse.quote_plus(match)
    smatch = match.replace(" ", "+")
    search_args = str(smatch), page
    gsearch = GoogleSearch()
    bsearch = BingSearch()
    ysearch = YahooSearch()
    try:
        gresults = await gsearch.async_search(*search_args)
    except NoResultsOrTrafficError:
        try:
            gresults = await bsearch.async_search(*search_args)
        except NoResultsOrTrafficError:
            try:
                gresults = await ysearch.async_search(*search_args)
            except Exception as e:
                return await edit_delete(zedevent, f"**- Ø®Ø·Ù€Ø£ :**\n`{e}`", time=10)
    msg = ""
    for i in range(lim):
        if i > len(gresults["links"]):
            break
        try:
            title = gresults["titles"][i]
            link = gresults["links"][i]
            desc = gresults["descriptions"][i]
            msg += f"ğŸ‘‰[{title}]({link})\n`{desc}`\n\n"
        except IndexError:
            break
    await edit_or_reply(
        zedevent,
        "**- Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù€Ù€Ù„ :**\n`" + match + "`\n\n**- Ø§Ù„Ù†ØªØ§Ø¦Ù€Ø¬ :**\n" + msg,
        link_preview=False,
        aslink=True,
        linktext=f"**- Ù†ØªÙ€Ø§Ø¦Ù€Ø¬ Ø§Ù„Ø¨Ø­Ù€Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ù€Ù€Ù‡ **__{match}__ **Ù‡Ù€ÙŠ :**",
    )
    if BOTLOG:
        await q_event.client.send_message(
            BOTLOG_CHATID,
            f"**- ØªÙ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ù€Ù‡ ** `{match}` **Ø¨Ù†Ø¬Ù€Ø§Ø­âœ“**",
        )


@zedub.zed_cmd(
    pattern="Ù…ØµØ§Ø¯Ø± ([\s\S]*)",
    command=("Ù…ØµØ§Ø¯Ø±", plugin_category),
    info={
        "header": "Google search in image format",
        "Ø§Ù„Ø§Ø³Ù€ØªØ®Ù€Ø¯Ø§Ù…": "{tr}gis <query>",
        "Ù…Ø«Ù€Ù€Ø§Ù„": "{tr}gis cat",
    },
)
async def _(event):
    "To search in google and send result in picture."


@zedub.zed_cmd(
    pattern="Ù…ØµØ§Ø¯Ø±$",
    command=("Ù…ØµØ§Ø¯Ø±", plugin_category),
    info={
        "header": "Google reverse search command.",
        "Ø§Ù„Ø§Ø³Ù€ØªØ®Ù€Ø¯Ø§Ù…": "{tr}grs",
    },
)
async def grs(event):
    "Google Reverse Search"
    start = datetime.now()
    OUTPUT_STR = "Reply to an image to do Google Reverse Search"
    if event.reply_to_msg_id:
        zedevent = await edit_or_reply(event, "Pre Processing Media")
        previous_message = await event.get_reply_message()
        previous_message_text = previous_message.message
        BASE_URL = "http://www.google.com"
        if previous_message.media:
            photo = await Convert.to_image(
                event,
                previous_message,
                dirct="./temp",
                file="grs.png",
            )
            if photo[1] is None:
                return await edit_delete(
                    photo[0], "__Unable to extract image from the replied message.__"
                )
            SEARCH_URL = f"{BASE_URL}/searchbyimage/upload"
            multipart = {
                "encoded_image": (
                    photo[1],
                    open(photo[1], "rb"),
                ),
                "image_content": "",
            }
            # https://stackoverflow.com/a/28792943/4723940
            google_rs_response = requests.post(
                SEARCH_URL, files=multipart, allow_redirects=False
            )
            the_location = google_rs_response.headers.get("Location")
            os.remove(photo[1])
        else:
            previous_message_text = previous_message.message
            SEARCH_URL = "{}/searchbyimage?image_url={}"
            request_url = SEARCH_URL.format(BASE_URL, previous_message_text)
            google_rs_response = requests.get(request_url, allow_redirects=False)
            the_location = google_rs_response.headers.get("Location")
        await zedevent.edit("Found Google Result. Pouring some soup on it!")
        headers = {
            "User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0"
        }
        response = requests.get(the_location, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        # document.getElementsByClassName("r5a77d"): PRS
        try:
            prs_div = soup.find_all("div", {"class": "r5a77d"})[0]
            prs_anchor_element = prs_div.find("a")
            prs_url = BASE_URL + prs_anchor_element.get("href")
            prs_text = prs_anchor_element.text
            # document.getElementById("jHnbRc")
            img_size_div = soup.find(id="jHnbRc")
            img_size = img_size_div.find_all("div")
        except Exception:
            return await edit_delete(
                zedevent, "`Sorry. I am unable to find similar images`"
            )
        end = datetime.now()
        ms = (end - start).seconds
        OUTPUT_STR = """{img_size}
<b>Possible Related Search : </b> <a href="{prs_url}">{prs_text}</a> 
<b>More Info : </b> Open this <a href="{the_location}">Link</a> 
<i>fetched in {ms} seconds</i>""".format(
            **locals()
        )
    else:
        zedevent = event
    await edit_or_reply(zedevent, OUTPUT_STR, parse_mode="HTML", link_preview=False)


@zedub.zed_cmd(
    pattern="ØªØ­Ù„ÙŠÙ„(?:\s|$)([\s\S]*)",
    command=("ØªØ­Ù„ÙŠÙ„", plugin_category),
    info={
        "header": "Google reverse search command.",
        "Ø§Ù„ÙˆØµÙ€Ù": "reverse search replied image or sticker in google and shows results. if count is not used then it send 1 image by default.",
        "Ø§Ù„Ø§Ø³ØªØ®Ù€Ø¯Ø§Ù…": "{tr}reverse <count>",
    },
)
async def reverse(event):
    "Google Reverse Search"
    reply_to = await reply_id(event)
    if os.path.isfile("okgoogle.png"):
        os.remove("okgoogle.png")
    message = await event.get_reply_message()
    if not message and not message.media:
        return await edit_or_reply(event, "**Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ€ÙˆØ±Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø´Ø¨ÙŠÙ‡Ø§ØªÙ‡Ø§ ÙÙŠ Ø¬ÙˆØ¬Ù„ Ø±ÙŠÙ€ÙØ±Ø³**")
    photo = await Convert.to_image(
        event,
        message,
        dirct="./temp",
        file="reverse.png",
    )
    if photo[1] is None:
        return await edit_delete(
            photo[0], "__Unable to extract image from the replied message.__"
        )
    catevent = await edit_or_reply(event, "** âŒ”âˆ®Ø¬Ù€Ø§Ø±Ù Ø§Ù„Ø¨Ù€Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± ğŸ†â™¥ï¸ ...**")
    try:
        image = Image.open(photo[1])
        os.remove(photo[1])
    except OSError:
        return await catevent.edit("**- Ù…Ù„Ù ØºÙŠÙ€Ø± Ù…Ø¯Ø¹Ù€ÙˆÙ… ØŸ!**")
    name = "okgoogle.png"
    image.save(name, "PNG")
    image.close()

    # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ (Ù…Ø¨Ø¯Ø¦ÙŠÙ‹Ø§ 3 Ø¥Ø°Ø§ Ù„Ù… ÙŠÙÙƒØªØ¨ Ø¹Ø¯Ø¯)
    lim = event.pattern_match.group(1) or 3
    try:
        lim = int(lim)
    except Exception:
        lim = 3

    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø¹Ù„Ù‰ Google (Ù…Ø¹ fallback ØªÙˆØ¶ÙŠØ­ÙŠ)
    source, results, fetchUrl = await reverse_image_search(name, lim=int(lim))

    if source == "google":
        # Ù†ØªØ§Ø¦Ø¬ Google Ù‡ÙŠ dict Ù…Ù† ParseSauce: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ best_guess Ùˆ similar_images
        guess = results.get("best_guess", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ®Ù…ÙŠÙ†")
        imgspage = results.get("similar_images", "")
        # Ø§Ø³ØªØ®Ø¯Ù… fetchUrl Ø§Ù„Ù…Ø¹Ø§Ø¯ Ù„Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ù„Ùˆ ÙˆÙØ¬Ø¯)
        if fetchUrl:
            await catevent.edit(f"[{guess}]({fetchUrl})\n\n**Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© ...**")
        else:
            await catevent.edit(f"**Ø£ÙØ¶Ù„ ØªØ®Ù…ÙŠÙ†:** {guess}\n\n**Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© ...**")

        # Ø¬Ù„Ø¨ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ø«Ù… Ø¥Ø±Ø³Ø§Ù„Ù‡Ù€Ø§
        images = await scam(results, lim)
        yeet = []
        for i in images:
            try:
                k = requests.get(i, timeout=30)
                yeet.append(k.content)
            except Exception:
                # ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ø±Ø§Ø¨Ø· ÙØ§Ø´Ù„
                continue

        with contextlib.suppress(TypeError):
            await event.client.send_file(
                entity=await event.client.get_input_entity(event.chat_id),
                file=yeet,
                reply_to=reply_to,
            )

        # Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© (Ø¥Ù† ÙˆÙØ¬Ø¯)
        if imgspage:
            if fetchUrl:
                await catevent.edit(
                    f"[{guess}]({fetchUrl})\n\n[Ù„ØµÙ€ÙˆØ± Ù…Ø´Ø§Ø¨Ù‡Ù€Ù‡ Ø§Ø®Ù€Ø±Ù‰ Ø§Ø¶ØºØ· Ù‡Ù†Ø§...]({imgspage})"
                )
            else:
                await catevent.edit(
                    f"**Ø£ÙØ¶Ù„ ØªØ®Ù…ÙŠÙ†:** {guess}\n\n[Ù„ØµÙ€ÙˆØ± Ù…Ø´Ø§Ø¨Ù‡Ù€Ù‡ Ø§Ø®Ù€Ø±Ù‰ Ø§Ø¶ØºØ· Ù‡Ù†Ø§...]({imgspage})"
                )
    elif source == "bing":
        # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ù„Ø£Ù†Ù†Ø§ Ù„Ø§ Ù†Ù…Ù„Ùƒ Ø¨Ø­Ø« Ø¹ÙƒØ³ÙŠ Ù…Ø¨Ø§Ø´Ø± Ù‡Ù†Ø§
        # results Ù‡Ùˆ Ù‚Ø§Ø¦Ù…Ø© Ø±Ø³Ø§Ø¦Ù„ Ø¥ÙŠØ¶Ø§Ø­ÙŠØ©
        msg = "\n".join(results) if isinstance(results, (list, tuple)) else str(results)
        await catevent.edit(f"âœ§ fallback (Bing) â€” Ù…Ù„Ø§Ø­Ø¸Ø©:\n\n{msg}")
    else:
        # fallback Ø¹Ø§Ù… Ø£Ùˆ yandex
        msg = results[0] if isinstance(results, (list, tuple)) else str(results)
        await catevent.edit(f"âœ§ fallback (Yandex) â€” Ù…Ù„Ø§Ø­Ø¸Ø©:\n\n{msg}")

    # Ø§Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
    try:
        os.remove(name)
    except Exception:
        pass


@zedub.zed_cmd(
    pattern="Ø¬ÙˆØ¬Ù„(?:\s|$)([\s\S]*)",
    command=("Ø¬ÙˆØ¬Ù„", plugin_category),
    info={
        "header": "To get link for google search",
        "Ø§Ù„Ø§Ø³Ù€ØªØ®Ù€Ø¯Ø§Ù…": [
            "{tr}Ø¬ÙˆØ¬Ù„ + ÙƒÙ„Ù…Ù€Ù‡",
        ],
    },
)
async def google_search(event):
    "Will show you google search link of the given query."
    input_str = event.pattern_match.group(1)
    reply_to_id = await reply_id(event)
    if not input_str:
        return await edit_delete(
            event, "**- Ù‚Ù… Ø¨Ø§Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ù€Ø© Ù„Ù„Ø¨Ø­Ø« ...**"
        )
    input_str = deEmojify(input_str).strip()
    if len(input_str) > 195 or len(input_str) < 1:
        return await edit_delete(
            event,
            "__Plox your search query exceeds 200 characters or you search query is empty.__",
        )
    query = f"#12{input_str}"
    results = await event.client.inline_query("@StickerizerBot", query)
    await results[0].click(event.chat_id, reply_to=reply_to_id, hide_via=True)
    await event.delete()

AsheqSearch_cmd = (
"[á¯“ ğ—¬ğ—®ğ—ºğ—²ğ—»ğ—§ğ—µğ—¼ğ—» ğ—¨ğ˜€ğ—²ğ—¿ğ—¯ğ—¼ğ˜ - Ø§ÙˆØ§Ù…Ù€Ù€Ø± Ø§Ù„Ø¨Ø­Ù€Ù€Ø« ğŸ” ](t.me/YamenThon) ."
"**â‹†â”€â”„â”€â”„â”€â”„â”€â”„â”€â”€â”„â”€â”„â”€â”„â”€â”„â”€â‹†**\n"

"âš‰ `.Ø¬Ùˆ <ÙƒÙ„Ù…Ø©>`\n"
"**âª¼ Ø§Ù„ÙˆØµÙ:** Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„ (Ù…Ø¹ Ø¯Ø¹Ù… ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØµÙØ­Ø©).\n"
"**âª¼ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**\n"
"`.Ø¬Ùˆ ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†`\n"
"`.Ø¬Ùˆ Ø¹Ø¯Ø¯6 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†`\n"
"`.Ø¬Ùˆ ØµÙØ­Ù‡2 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†`\n"
"`.Ø¬Ùˆ ØµÙØ­Ù‡2 Ø¹Ø¯Ø¯7 ØµØ¯Ø§Ù… Ø­Ø³ÙŠÙ†`\n\n"

"âš‰ `.Ù…ØµØ§Ø¯Ø± <ÙƒÙ„Ù…Ø©>`\n"
"**âª¼ Ø§Ù„ÙˆØµÙ:** Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„ ØµÙˆØ± (Google Image Search).\n"
"**âª¼ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**\n"
"`.Ù…ØµØ§Ø¯Ø± Ù‚Ø·Ø©`\n\n"

"âš‰ `.Ù…ØµØ§Ø¯Ø±` Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ ØµÙˆØ±Ø©\n"
"**âª¼ Ø§Ù„ÙˆØµÙ:** Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ ÙÙŠ Ø¬ÙˆØ¬Ù„ (Google Reverse Search) Ø¹Ù† ØµÙˆØ±Ø© Ø£Ùˆ Ø±Ø§Ø¨Ø· ØµÙˆØ±Ø©.\n"
"**âª¼ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** Ù‚Ù… Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© Ø£Ùˆ Ù…Ù„ØµÙ‚ Ø«Ù… Ø£Ø±Ø³Ù„ `.Ù…ØµØ§Ø¯Ø±`\n\n"

"âš‰ `.ØªØ­Ù„ÙŠÙ„ <Ø¹Ø¯Ø¯>`\n"
"**âª¼ Ø§Ù„ÙˆØµÙ:** Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ (Reverse) Ù„Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø¬ÙˆØ¬Ù„ ÙˆØ¹Ø±Ø¶ ØµÙˆØ± Ù…Ø´Ø§Ø¨Ù‡Ø©.\n"
"**âª¼ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** Ù‚Ù… Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© ÙˆØ£Ø±Ø³Ù„:\n"
"`.ØªØ­Ù„ÙŠÙ„ 3` (ÙŠØ¬ÙŠØ¨ 3 ØµÙˆØ± Ù…Ø´Ø§Ø¨Ù‡Ø©)\n"
"Ø¥Ø°Ø§ Ù…Ø§ ÙƒØªØ¨Øª Ø§Ù„Ø¹Ø¯Ø¯ØŒ ÙŠØªÙ… Ø§ÙØªØ±Ø§Ø¶ Ø§Ù„Ø¹Ø¯Ø¯ = 3.\n\n"

"âš‰ `.Ø¬ÙˆØ¬Ù„ <ÙƒÙ„Ù…Ø©>`\n"
"**âª¼ Ø§Ù„ÙˆØµÙ:** Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø± Ù„Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù„ Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.\n"
"**âª¼ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**\n"
"`.Ø¬ÙˆØ¬Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ`\n\n"

"**âª¼ Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙˆØ§Ù…Ø± ØªØºØ·ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ + Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙˆØ± + Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠØŒ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ù…Ø³ØªÙ…Ø±Ø© âœ“ğŸ“¥**\n\n"
)

@zedub.zed_cmd(pattern="Ø§Ù„Ø¨Ø­Ø«")
async def cmd(asheqqqq):
    await edit_or_reply(asheqqqq, AsheqSearch_cmd)
